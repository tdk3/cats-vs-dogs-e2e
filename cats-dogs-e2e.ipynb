{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('train')\n",
    "dogs = [x for x in files if x.find('dog') != -1]\n",
    "cats = [x for x in files if x.find('cat') != -1]\n",
    "targets = [dogs, cats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "**Link:**\n",
    "\n",
    "There are 12,500 images of each species contained. Images are larger than thumbnails and are of a variety of breeds. Angles, colors, position are incidental to each photograph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def to_gray(color_img):\n",
    "    gray = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def generate_sift(gray_img):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, desc = sift.detectAndCompute(gray_img, None)\n",
    "    return kp, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread('train/' + dogs[1])\n",
    "#img = to_gray(img)\n",
    "#kp1, desc1 = generate_sift(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"desc_0:\", len(desc))\n",
    "#print(\"desc_1:\", len(desc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(np.vstack((desc,desc1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting keypoint descriptors from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_desc(file, path='train/'):\n",
    "    \n",
    "    img = cv2.imread(path + file)\n",
    "    img = to_gray(img)\n",
    "    \n",
    "    kp, desc = generate_sift(img)\n",
    "    \n",
    "    num_desc = desc.shape[0]\n",
    "    images = np.full((num_desc,1), file)\n",
    "    \n",
    "    return images, kp, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extract(file_list):\n",
    "    \n",
    "    num_of_files = len(file_list)\n",
    "    i = 1\n",
    "    desc_total = None\n",
    "    kp_total = None\n",
    "    img_total = None\n",
    "    \n",
    "    for file in file_list:\n",
    "        \n",
    "        # Extract all SIFT keypoints and descriptors\n",
    "        images, kp, desc = extract_desc(file)\n",
    "        \n",
    "        if i == 1:\n",
    "            kp_total = kp\n",
    "            desc_total = desc\n",
    "            img_total = images\n",
    "            clear_output(wait=True)\n",
    "            print(i, \"/\", num_of_files, \"completed\")\n",
    "            i = i + 1\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            kp_total = np.append(kp_total, kp)\n",
    "            desc_total = np.vstack((desc_total, desc))\n",
    "            img_total = np.vstack((img_total, images))\n",
    "            clear_output(wait=True)\n",
    "            print(i, \"/\", num_of_files, \"completed\")\n",
    "            i = i + 1\n",
    "    \n",
    "    \n",
    "    return img_total, kp_total, desc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 / 500 completed\n"
     ]
    }
   ],
   "source": [
    "dog_img, dog_kp, dog_desc = run_extract(dogs[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 / 500 completed\n"
     ]
    }
   ],
   "source": [
    "cat_img, cat_kp, cat_desc = run_extract(cats[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.7286376953125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_kp[0].angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333474, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data\n",
    "Comment out if not needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Cats\n",
    "np.save('data/20190120-sampledesc-cats', cat_desc)\n",
    "np.save('data/20190120-img-cats', cat_img)\n",
    "\n",
    "# Save Dogs\n",
    "np.save('data/20190120-sampledesc-dogs', dog_desc)\n",
    "#np.save('20190120-kmeans-samplelabels-dogs', dog_labels)\n",
    "#np.save('20190120-kmeans-samplecenters-dogs', centers)\n",
    "np.save('data/20190120-img-dogs', dog_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the cv2 method below, it was far too slow on my macbook, engineering laptop, and lab desktop computer. I opted to use AWS Sagemaker for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criteria = ( type, max_iter = 10 , epsilon = 1.0 )\n",
    "#criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "\n",
    "# Set flags (Just to avoid line break in the code)\n",
    "#flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "# Apply KMeans\n",
    "#compactness, dog_lab, dog_cen = cv2.kmeans(dog_desc ,1000,None,criteria,10,flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an S3 instance and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket\n",
    "#bucket = 'cats-vs-dogs-descriptors' # '<user-data-bucket>' # replace with your bucket name'\n",
    "bucket = 'sagemaker-catsvsdogs-east-1'\n",
    "prefix = 'sagemaker/DEMO-kmeans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_data(filename):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket('cats-vs-dogs-descriptors').download_file(filename, '.desc.npy')\n",
    "    a = np.load('.desc.npy')\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = 'sampledesc-dogs.npy'\n",
    "dog_desc = get_s3_data(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436862, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_desc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data load was successfull, the next step is to try out a plain vanilla configuration of AWS SageMaker (K-Means) with 1000 clusters. This will give me feel for how much time is saved by using AWS and also if any cost in incurred. \n",
    "\n",
    "Further efforts could focus around tuning the hyperparameters and building a more robust dictionary (i.e. more images and descriptors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker k-means ECR images ARNs \n",
    "images = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/kmeans:latest',\n",
    "          'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/kmeans:latest',\n",
    "          'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/kmeans:latest',\n",
    "          'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/kmeans:latest'}\n",
    "image = images[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to IO format for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_s3_data(bucket, prefix, channel, X):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(buf, X.astype('float32'))\n",
    "    buf.seek(0)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, channel + '.data')).upload_fileobj(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_s3_data(bucket, prefix, 'train', dog_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Low-Level SDK method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'arn:aws:iam::536197384257:role/service-role/AmazonSageMaker-ExecutionRole-20190129T171919'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job kmeans-lowlevel-2019-01-30-08-36-33\n"
     ]
    }
   ],
   "source": [
    "job_name = 'kmeans-lowlevel-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://sagemaker-catsvsdogs-east-1/kmeans_lowlevel_example/output\n",
      "InProgress\n",
      "Training job ended with status: Completed\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "image = get_image_uri(boto3.Session().region_name, 'kmeans')\n",
    "\n",
    "output_location = 's3://{}/kmeans_lowlevel_example/output'.format(bucket)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "\n",
    "k = '1000'\n",
    "features = '128'\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": output_location\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 2,\n",
    "        \"InstanceType\": \"ml.c4.8xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"k\": k,\n",
    "        \"feature_dim\": features,\n",
    "        \"mini_batch_size\": \"500\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 60 * 60\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/train.data\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "sagemaker.create_training_job(**create_training_params)\n",
    "\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "\n",
    "try:\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "finally:\n",
    "    status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "    if status == 'Failed':\n",
    "        message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "        print('Training failed with the following error: {}'.format(message))\n",
    "        raise Exception('Training job failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect SageMaker output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((array([6.910e+02, 1.000e+00, 2.130e+02, 1.300e+01, 7.000e+02, 6.440e+02,\n",
       "         1.350e+02, 6.000e+00, 5.000e+00, 3.860e+02, 1.400e+01, 6.000e+01,\n",
       "         3.730e+02, 1.210e+02, 2.930e+02, 1.070e+02, 1.750e+02, 2.350e+02,\n",
       "         1.020e+02, 3.840e+02, 1.190e+02, 3.510e+02, 1.430e+02, 5.600e+02,\n",
       "         1.350e+02, 3.080e+02, 7.780e+02, 7.500e+01, 2.130e+02, 1.500e+02,\n",
       "         1.800e+01, 1.480e+02, 7.710e+02, 1.070e+02, 1.910e+02, 6.410e+02,\n",
       "         3.310e+02, 1.290e+02, 4.380e+02, 6.660e+02, 2.409e+03, 2.120e+02,\n",
       "         1.330e+02, 8.100e+01, 1.780e+02, 3.890e+02, 1.410e+02, 2.630e+02,\n",
       "         1.790e+02, 1.620e+02, 1.300e+02, 1.400e+02, 2.318e+03, 2.060e+02,\n",
       "         2.210e+02, 3.280e+02, 1.080e+02, 1.380e+02, 3.380e+02, 1.170e+02,\n",
       "         2.290e+02, 2.016e+03, 3.450e+02, 1.530e+02, 3.630e+02, 1.190e+02,\n",
       "         9.000e+01, 1.100e+02, 2.230e+02, 1.490e+02, 2.100e+02, 1.240e+02,\n",
       "         1.030e+02, 1.840e+02, 7.710e+02, 1.580e+02, 3.070e+02, 1.820e+02,\n",
       "         4.600e+01, 2.040e+02, 3.310e+02, 1.135e+03, 3.740e+02, 1.902e+03,\n",
       "         1.650e+02, 5.360e+02, 8.900e+01, 1.160e+02, 5.800e+02, 1.620e+02,\n",
       "         1.020e+02, 3.230e+02, 1.780e+02, 3.320e+02, 2.680e+02, 4.180e+02,\n",
       "         4.790e+02, 1.650e+02, 3.250e+02, 1.890e+02, 1.190e+02, 1.760e+02,\n",
       "         2.130e+02, 1.000e+00, 2.040e+02, 1.320e+02, 3.030e+02, 1.830e+02,\n",
       "         1.580e+02, 9.200e+01, 2.270e+02, 1.840e+02, 1.900e+02, 1.690e+02,\n",
       "         1.470e+02, 2.110e+02, 1.780e+02, 3.760e+02, 6.900e+01, 2.340e+02,\n",
       "         6.000e+01, 3.340e+02, 2.840e+02, 3.060e+02, 2.230e+02, 2.830e+02,\n",
       "         2.170e+02, 3.750e+02, 1.700e+02, 1.890e+02, 2.560e+02, 4.830e+02,\n",
       "         3.020e+02, 1.940e+02, 2.350e+02, 6.500e+01, 3.560e+02, 7.800e+01,\n",
       "         1.670e+02, 3.210e+02, 1.570e+02, 8.330e+02, 1.280e+02, 3.440e+02,\n",
       "         4.560e+02, 5.170e+02, 2.090e+02, 5.440e+02, 1.710e+02, 1.310e+02,\n",
       "         5.970e+02, 4.330e+02, 1.650e+02, 2.490e+02, 5.370e+02, 3.260e+02,\n",
       "         1.120e+02, 1.900e+02, 1.300e+02, 8.070e+02, 1.080e+02, 3.740e+02,\n",
       "         2.400e+02, 1.410e+02, 5.560e+02, 1.600e+02, 1.870e+02, 4.470e+02,\n",
       "         4.610e+02, 8.100e+01, 2.080e+02, 2.880e+02, 9.400e+01, 2.020e+02,\n",
       "         1.620e+02, 1.650e+02, 2.910e+02, 2.260e+02, 1.310e+02, 1.290e+02,\n",
       "         2.840e+02, 2.770e+02, 2.330e+02, 2.480e+02, 1.580e+02, 8.000e+01,\n",
       "         6.020e+02, 5.940e+02, 4.940e+02, 5.510e+02, 2.440e+02, 1.520e+02,\n",
       "         3.500e+02, 6.000e+01, 9.920e+02, 5.040e+02, 1.210e+02, 9.300e+01,\n",
       "         9.380e+02, 1.580e+02, 1.730e+02, 4.860e+02, 2.020e+02, 2.740e+02,\n",
       "         1.860e+02, 2.920e+02, 2.320e+02, 1.710e+02, 4.620e+02, 1.490e+02,\n",
       "         1.740e+02, 9.300e+01, 1.635e+03, 2.220e+02, 2.150e+02, 1.010e+02,\n",
       "         8.400e+01, 1.500e+02, 3.050e+02, 2.590e+02, 3.810e+02, 1.060e+02,\n",
       "         1.340e+02, 1.910e+02, 1.130e+02, 1.540e+02, 1.490e+02, 7.960e+02,\n",
       "         1.930e+02, 2.590e+02, 1.670e+02, 3.350e+02, 2.430e+02, 2.630e+02,\n",
       "         2.320e+02, 4.770e+02, 3.210e+02, 1.910e+02, 2.120e+02, 2.640e+02,\n",
       "         2.960e+02, 1.830e+02, 1.690e+02, 5.780e+02, 3.090e+02, 2.120e+02,\n",
       "         2.730e+02, 3.630e+02, 2.920e+02, 2.230e+02, 2.660e+02, 1.650e+02,\n",
       "         2.340e+02, 2.140e+02, 4.110e+02, 2.600e+02, 3.950e+02, 1.530e+02,\n",
       "         1.910e+02, 1.210e+02, 3.430e+02, 5.370e+02, 1.910e+02, 2.920e+02,\n",
       "         2.260e+02, 2.690e+02, 1.883e+03, 3.570e+02, 1.340e+02, 1.980e+02,\n",
       "         3.740e+02, 2.320e+02, 2.850e+02, 2.160e+02, 2.660e+02, 1.940e+02,\n",
       "         3.280e+02, 4.780e+02, 9.090e+02, 1.820e+02, 1.900e+02, 4.770e+02,\n",
       "         2.770e+02, 1.500e+02, 2.230e+02, 2.650e+02, 1.303e+03, 1.960e+02,\n",
       "         2.550e+02, 1.830e+02, 2.130e+02, 2.740e+02, 3.580e+02, 1.440e+02,\n",
       "         2.460e+02, 4.300e+01, 3.920e+02, 1.720e+02, 3.730e+02, 9.700e+01,\n",
       "         1.450e+02, 3.000e+02, 3.940e+02, 4.080e+02, 2.292e+03, 2.370e+02,\n",
       "         3.700e+02, 1.660e+02, 3.810e+02, 3.000e+02, 3.460e+02, 2.370e+02,\n",
       "         2.620e+02, 2.580e+02, 1.400e+02, 2.430e+02, 2.790e+02, 3.420e+02,\n",
       "         4.820e+02, 5.940e+02, 2.000e+02, 1.330e+02, 8.220e+02, 1.340e+02,\n",
       "         2.310e+02, 1.500e+02, 1.840e+02, 4.740e+02, 1.670e+02, 2.440e+02,\n",
       "         6.250e+02, 9.670e+02, 3.890e+02, 4.080e+02, 6.800e+01, 4.610e+02,\n",
       "         1.780e+02, 1.440e+02, 4.360e+02, 3.300e+02, 2.510e+02, 2.530e+02,\n",
       "         2.090e+02, 1.850e+02, 6.550e+02, 1.040e+02, 2.860e+02, 2.140e+02,\n",
       "         3.860e+02, 1.760e+02, 4.480e+02, 1.430e+02, 5.020e+02, 2.120e+02,\n",
       "         3.240e+02, 3.980e+02, 2.280e+02, 1.420e+02, 1.200e+02, 3.480e+02,\n",
       "         1.670e+02, 2.120e+02, 3.390e+02, 3.170e+02, 2.850e+02, 3.440e+02,\n",
       "         1.950e+02, 1.610e+02, 1.610e+02, 1.460e+02, 1.480e+02, 1.510e+03,\n",
       "         4.260e+02, 3.300e+02, 3.020e+02, 3.260e+02, 2.100e+02, 5.310e+02,\n",
       "         3.410e+02, 3.520e+02, 3.140e+02, 2.410e+02, 1.730e+02, 4.980e+02,\n",
       "         1.490e+02, 2.210e+02, 2.310e+02, 1.840e+02, 1.820e+02, 1.380e+02,\n",
       "         2.090e+02, 2.290e+02, 4.030e+02, 2.290e+02, 2.570e+02, 1.043e+03,\n",
       "         5.910e+02, 2.590e+02, 2.550e+02, 1.000e+01, 3.100e+02, 2.450e+02,\n",
       "         3.210e+02, 4.080e+02, 1.870e+02, 1.040e+02, 2.170e+02, 1.970e+02,\n",
       "         2.760e+02, 8.170e+02, 1.890e+02, 1.360e+02, 1.520e+02, 2.700e+02,\n",
       "         1.950e+02, 3.510e+02, 4.620e+02, 2.110e+02, 1.870e+02, 3.380e+02,\n",
       "         3.080e+02, 1.450e+02, 2.340e+02, 4.580e+02, 4.940e+02, 2.070e+02,\n",
       "         4.520e+02, 1.615e+03, 6.940e+02, 2.450e+02, 2.670e+02, 3.130e+02,\n",
       "         2.240e+02, 2.570e+02, 6.150e+02, 1.710e+02, 3.870e+02, 6.500e+01,\n",
       "         9.110e+02, 1.480e+02, 9.900e+02, 2.800e+01, 4.770e+02, 3.170e+02,\n",
       "         2.180e+02, 2.650e+02, 3.260e+02, 1.990e+02, 2.980e+02, 1.170e+02,\n",
       "         1.670e+02, 2.310e+02, 2.030e+02, 1.550e+02, 2.720e+02, 2.930e+02,\n",
       "         4.010e+02, 2.260e+02, 2.500e+02, 2.190e+02, 1.600e+02, 2.890e+02,\n",
       "         2.140e+02, 2.760e+02, 2.910e+02, 2.160e+02, 1.150e+02, 1.440e+02,\n",
       "         1.780e+02, 2.510e+02, 2.100e+02, 1.980e+02, 6.840e+02, 1.510e+02,\n",
       "         5.910e+02, 2.410e+02, 1.540e+02, 2.960e+02, 2.230e+02, 1.560e+02,\n",
       "         2.200e+02, 1.950e+02, 2.050e+02, 1.640e+02, 1.076e+03, 4.250e+02,\n",
       "         4.340e+02, 4.670e+02, 1.860e+02, 3.000e+02, 2.430e+02, 2.130e+02,\n",
       "         1.380e+02, 4.690e+02, 8.140e+02, 4.360e+02, 3.130e+02, 3.270e+02,\n",
       "         1.660e+02, 2.480e+02, 2.970e+02, 3.260e+02, 2.210e+02, 1.440e+02,\n",
       "         1.020e+02, 5.670e+02, 3.660e+02, 2.390e+02, 1.930e+02, 1.910e+02,\n",
       "         1.460e+02, 2.220e+02, 3.020e+02, 2.340e+02, 1.420e+02, 1.680e+02,\n",
       "         4.490e+02, 2.250e+02, 1.790e+02, 4.630e+02, 6.780e+02, 3.580e+02,\n",
       "         4.140e+02, 3.930e+02, 2.120e+02, 2.950e+02, 2.500e+02, 2.740e+02,\n",
       "         6.170e+02, 2.580e+02, 1.670e+02, 3.560e+02, 1.031e+03, 2.730e+02,\n",
       "         2.300e+02, 1.140e+02, 1.990e+02, 4.170e+02, 3.710e+02, 1.790e+02,\n",
       "         3.160e+02, 1.850e+02, 8.830e+02, 4.180e+02, 1.460e+02, 1.810e+02,\n",
       "         2.160e+02, 2.630e+02, 1.930e+02, 3.050e+02, 3.790e+02, 7.250e+02,\n",
       "         4.970e+02, 3.200e+02, 2.200e+02, 1.480e+02, 2.580e+02, 2.380e+02,\n",
       "         2.470e+02, 1.830e+02, 1.370e+02, 2.950e+02, 1.570e+02, 1.920e+02,\n",
       "         2.300e+02, 6.570e+02, 5.790e+02, 1.870e+02, 2.850e+02, 3.510e+02,\n",
       "         5.390e+02, 2.300e+02, 3.610e+02, 1.330e+02, 1.710e+02, 1.780e+02,\n",
       "         6.240e+02, 2.660e+02, 1.890e+02, 3.340e+02, 4.340e+02, 3.920e+02,\n",
       "         5.100e+02, 1.620e+02, 2.224e+03, 6.360e+02, 2.540e+02, 7.040e+02,\n",
       "         4.140e+02, 3.520e+02, 5.060e+02, 3.920e+02, 3.700e+02, 2.280e+02,\n",
       "         3.580e+02, 7.870e+02, 3.060e+02, 2.070e+02, 2.850e+02, 3.210e+02,\n",
       "         7.110e+02, 1.250e+02, 1.220e+02, 2.810e+02, 5.110e+02, 2.100e+02,\n",
       "         6.830e+02, 7.900e+01, 2.450e+02, 2.790e+02, 1.580e+02, 6.560e+02,\n",
       "         3.880e+02, 2.810e+02, 2.060e+02, 2.900e+02, 2.550e+02, 9.840e+02,\n",
       "         4.510e+02, 2.140e+02, 4.797e+03, 2.200e+02, 2.270e+02, 2.290e+02,\n",
       "         2.840e+02, 2.720e+02, 5.820e+02, 3.360e+02, 1.320e+02, 1.500e+02,\n",
       "         4.270e+02, 1.390e+02, 3.200e+02, 2.180e+02, 4.920e+02, 3.170e+02,\n",
       "         2.110e+02, 1.104e+03, 1.850e+02, 2.100e+02, 2.390e+02, 1.370e+02,\n",
       "         1.790e+02, 2.760e+02, 2.150e+02, 2.780e+02, 2.280e+02, 1.610e+02,\n",
       "         3.400e+02, 2.353e+03, 2.290e+02, 8.530e+02, 1.760e+02, 3.150e+02,\n",
       "         6.960e+02, 2.620e+02, 2.640e+02, 5.460e+02, 2.440e+02, 1.520e+02,\n",
       "         3.730e+02, 5.230e+02, 1.660e+02, 3.020e+02, 2.510e+02, 3.300e+02,\n",
       "         3.010e+02, 2.220e+02, 1.600e+02, 7.730e+02, 3.350e+02, 4.480e+02,\n",
       "         1.410e+02, 2.430e+02, 8.250e+02, 3.320e+02, 1.980e+02, 2.490e+02,\n",
       "         9.900e+02, 3.020e+02, 5.180e+02, 2.020e+02, 2.840e+02, 2.640e+02,\n",
       "         2.550e+02, 1.500e+02, 3.220e+02, 2.060e+02, 1.870e+02, 3.990e+02,\n",
       "         3.090e+02, 1.580e+02, 3.220e+02, 1.020e+02, 2.130e+02, 3.030e+02,\n",
       "         1.500e+02, 1.690e+02, 6.620e+02, 4.000e+02, 4.120e+02, 2.220e+02,\n",
       "         3.620e+03, 1.730e+02, 1.200e+02, 3.010e+02, 6.460e+02, 3.010e+02,\n",
       "         2.650e+02, 2.480e+02, 4.240e+02, 3.500e+02, 4.290e+02, 4.070e+02,\n",
       "         2.210e+02, 4.500e+02, 1.640e+02, 4.850e+02, 1.390e+02, 1.260e+02,\n",
       "         2.890e+02, 3.190e+02, 9.170e+02, 2.570e+02, 1.037e+03, 2.220e+02,\n",
       "         1.860e+02, 3.250e+02, 5.930e+02, 3.650e+02, 2.960e+02, 2.280e+02,\n",
       "         2.210e+02, 1.940e+02, 1.960e+02, 4.350e+02, 4.560e+02, 3.340e+02,\n",
       "         3.800e+02, 2.550e+02, 5.970e+02, 2.070e+02, 3.850e+02, 2.180e+02,\n",
       "         1.052e+03, 1.740e+02, 2.580e+02, 1.890e+02, 1.890e+02, 1.870e+02,\n",
       "         4.680e+02, 1.380e+02, 3.100e+02, 1.540e+02, 2.820e+02, 3.870e+02,\n",
       "         3.060e+02, 1.810e+02, 3.130e+02, 4.370e+02, 1.900e+02, 2.670e+02,\n",
       "         7.750e+02, 1.326e+03, 6.930e+02, 2.060e+02, 2.190e+02, 1.930e+02,\n",
       "         2.550e+02, 2.530e+02, 1.970e+02, 3.170e+02, 1.700e+02, 2.630e+02,\n",
       "         2.540e+02, 2.180e+02, 1.730e+02, 2.240e+02, 4.660e+02, 2.090e+02,\n",
       "         2.460e+02, 3.030e+02, 3.240e+02, 5.250e+02, 2.370e+02, 2.750e+02,\n",
       "         2.240e+02, 2.480e+02, 7.180e+02, 5.630e+02, 4.360e+02, 2.500e+02,\n",
       "         3.850e+02, 3.410e+02, 1.760e+02, 1.630e+02, 4.650e+02, 2.570e+02,\n",
       "         2.320e+02, 2.560e+02, 1.000e+02, 2.500e+02, 1.820e+02, 1.650e+02,\n",
       "         6.090e+02, 2.100e+02, 2.370e+02, 5.130e+02, 2.220e+02, 1.520e+02,\n",
       "         2.740e+02, 3.170e+02, 3.240e+02, 3.050e+02, 2.380e+02, 4.290e+02,\n",
       "         4.240e+02, 4.400e+02, 1.970e+02, 7.520e+02, 2.300e+02, 3.690e+02,\n",
       "         1.180e+02, 2.370e+02, 2.620e+02, 4.520e+02, 2.000e+02, 3.870e+02,\n",
       "         4.160e+02, 3.730e+02, 3.520e+02, 1.900e+02, 2.470e+02, 2.220e+02,\n",
       "         4.430e+02, 3.790e+02, 1.550e+02, 1.421e+03, 2.370e+02, 1.920e+02,\n",
       "         2.260e+02, 2.010e+02, 2.470e+02, 4.740e+02, 1.360e+02, 1.482e+03,\n",
       "         3.180e+02, 3.690e+02, 4.760e+02, 2.950e+02, 4.920e+02, 3.170e+02,\n",
       "         6.700e+02, 2.900e+02, 3.040e+02, 2.370e+02, 2.970e+02, 5.270e+02,\n",
       "         3.440e+02, 3.880e+02, 2.230e+02, 3.280e+02, 3.590e+02, 2.740e+02,\n",
       "         1.440e+02, 2.250e+02, 7.600e+02, 3.210e+02, 3.010e+02, 1.450e+02,\n",
       "         2.220e+02, 3.210e+02, 6.590e+02, 1.880e+02, 3.930e+02, 2.880e+02,\n",
       "         5.070e+02, 3.040e+02, 5.040e+02, 2.310e+02, 3.200e+02, 2.730e+02,\n",
       "         2.180e+02, 3.250e+02, 2.030e+02, 2.180e+02, 3.050e+02, 4.230e+02,\n",
       "         3.240e+02, 8.970e+02, 3.170e+02, 2.070e+02, 2.100e+02, 2.330e+02,\n",
       "         4.600e+02, 4.680e+02, 1.950e+02, 8.080e+02, 3.560e+02, 1.890e+02,\n",
       "         1.920e+02, 1.950e+02, 1.660e+02, 2.960e+02, 1.670e+02, 2.490e+02,\n",
       "         7.180e+02, 5.510e+02, 1.290e+02, 1.380e+02, 3.700e+02, 2.230e+02,\n",
       "         7.180e+02, 3.200e+02, 3.200e+02, 3.390e+02, 2.020e+02, 2.560e+02,\n",
       "         2.090e+02, 3.100e+02, 2.080e+02, 2.530e+02, 1.220e+02, 2.670e+02,\n",
       "         2.660e+02, 3.680e+02, 2.370e+02, 5.250e+02, 2.020e+02, 2.210e+02,\n",
       "         2.670e+02, 4.820e+02, 2.940e+02, 3.340e+02, 1.470e+02, 2.330e+02,\n",
       "         2.800e+02, 5.780e+02, 2.610e+02, 2.340e+02, 2.250e+02, 5.100e+02,\n",
       "         5.910e+02, 1.530e+02, 2.650e+02, 4.400e+02, 1.960e+02, 2.680e+02,\n",
       "         2.690e+02, 4.210e+02, 2.700e+02, 5.320e+02, 3.780e+02, 6.040e+02,\n",
       "         1.900e+02, 2.510e+02, 5.290e+02, 1.690e+02, 2.900e+02, 4.460e+02,\n",
       "         5.830e+02, 2.580e+02, 3.980e+02, 2.350e+02, 1.400e+02, 6.850e+02,\n",
       "         2.150e+02, 5.400e+02, 1.670e+02, 4.220e+02, 5.330e+02, 2.980e+02,\n",
       "         3.650e+02, 3.790e+02, 1.360e+02, 4.660e+02, 5.080e+02, 3.050e+02,\n",
       "         2.900e+02, 2.100e+02, 4.420e+02, 3.930e+02, 2.680e+02, 3.320e+02,\n",
       "         2.490e+02, 2.290e+02, 2.630e+02, 1.920e+02, 5.380e+02, 1.910e+02,\n",
       "         3.420e+02, 5.820e+02, 1.780e+02, 3.500e+02, 2.750e+02, 5.480e+02,\n",
       "         1.310e+02, 3.630e+02, 4.050e+02, 2.780e+02]),\n",
       "  array([  0.   ,   0.999,   1.998, ..., 997.002, 998.001, 999.   ]),\n",
       "  <a list of 1000 Patch objects>),\n",
       " None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(labels, bins=1000),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(labels, columns=[\"desc_cats\"])\n",
    "top_500_cats = cdf[\"desc_cats\"].value_counts().nlargest(500).reset_index()['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_centers = centers[top_500_cats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFKlJREFUeJzt3X+sZGd93/H3J15+tKTCa9iu3F2r64gVyKkEtla2EVHV4rA2JMr6D4KMonpFV9o/6rakipSu2z+sQJBAquKA1Fhx8SYLohjHIbVlLNztQlRVKsbrmhr/wN2LgXhXtveGtZ0mKCQm3/4xz3UuZm/vzL1z59fzfkmje85znjnzPOfMzGfOc87MTVUhSerPT027AZKk6TAAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ3aNu0G/P+8+c1vrj179ky7GZI0Vx5++OE/raod69Wb6QDYs2cPJ0+enHYzJGmuJPneMPUcApKkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJo7e458adpNkBaCASBJnRoqAJJcmOTuJN9K8mSSdya5KMnxJKfa3+2tbpJ8KslSkkeTXLFqPQdb/VNJDm5VpyRJ6xv2COCTwJer6m3A24EngSPAiaraC5xo8wDvBfa222HgNoAkFwG3AFcBVwK3rISGJGny1g2AJG8E/jFwB0BV/VVVvQgcAI61aseA69v0AeAzNfA14MIkFwPXAser6lxVvQAcB64ba28kSUMb5gjgUmAZ+L0kjyT5dJI3ADur6tlW5zlgZ5veBTyz6v6nW9la5ZKkKRgmALYBVwC3VdXlwF/wt8M9AFRVATWOBiU5nORkkpPLy8vjWKUk6TyGCYDTwOmqerDN380gEJ5vQzu0v2fb8jPAJavuv7uVrVX+Y6rq9qraV1X7duxY9x/aSJI2aN0AqKrngGeSvLUVXQM8AdwLrFzJcxC4p03fC9zYrga6GnipDRU9AOxPsr2d/N3fyiRJUzDsv4T8V8DnkrwWeBr4EIPwuCvJIeB7wAda3fuB9wFLwA9aXarqXJKPAg+1eh+pqnNj6YUkaWRDBUBVfQPYd55F15ynbgE3rbGeo8DRURooSdoafhNYkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjo1VAAk+W6Sbyb5RpKTreyiJMeTnGp/t7fyJPlUkqUkjya5YtV6Drb6p5Ic3JouSZKGMcoRwD+tqndU1b42fwQ4UVV7gRNtHuC9wN52OwzcBoPAAG4BrgKuBG5ZCQ1J0uRtZgjoAHCsTR8Drl9V/pka+BpwYZKLgWuB41V1rqpeAI4D123i8SVJmzBsABTwX5M8nORwK9tZVc+26eeAnW16F/DMqvuebmVrlf+YJIeTnExycnl5ecjmSZJGtW3Iej9XVWeS/H3geJJvrV5YVZWkxtGgqroduB1g3759Y1mnJOknDXUEUFVn2t+zwB8xGMN/vg3t0P6ebdXPAJesuvvuVrZWuSRpCtYNgCRvSPL3VqaB/cBjwL3AypU8B4F72vS9wI3taqCrgZfaUNEDwP4k29vJ3/2tTJI0BcMMAe0E/ijJSv3/XFVfTvIQcFeSQ8D3gA+0+vcD7wOWgB8AHwKoqnNJPgo81Op9pKrOja0nkqSRrBsAVfU08PbzlH8fuOY85QXctMa6jgJHR2+mJGnc/CawJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpU0MHQJILkjyS5L42f2mSB5MsJflCkte28te1+aW2fM+qddzcyp9Kcu24OyNJGt4oRwAfBp5cNf8J4NaqegvwAnColR8CXmjlt7Z6JLkMuAH4WeA64HeSXLC55kuSNmqoAEiyG/gF4NNtPsC7gbtblWPA9W36QJunLb+m1T8A3FlVP6yq7wBLwJXj6IQkaXTDHgH8NvDrwN+0+TcBL1bVy23+NLCrTe8CngFoy19q9V8pP899JEkTtm4AJPlF4GxVPTyB9pDkcJKTSU4uLy9P4iElqUvDHAG8C/ilJN8F7mQw9PNJ4MIk21qd3cCZNn0GuASgLX8j8P3V5ee5zyuq6vaq2ldV+3bs2DFyhyRJw1k3AKrq5qraXVV7GJzE/UpV/QrwVeD9rdpB4J42fW+bpy3/SlVVK7+hXSV0KbAX+PrYeiJJGsm29aus6d8Cdyb5TeAR4I5Wfgfw2SRLwDkGoUFVPZ7kLuAJ4GXgpqr60SYeX5K0CSMFQFX9MfDHbfppznMVT1X9JfDLa9z/Y8DHRm2kJGn8/CawJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQzmPPkS9NuwnSljMAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tS6AZDk9Um+nuR/J3k8yW+08kuTPJhkKckXkry2lb+uzS+15XtWrevmVv5Ukmu3qlOSpPUNcwTwQ+DdVfV24B3AdUmuBj4B3FpVbwFeAA61+oeAF1r5ra0eSS4DbgB+FrgO+J0kF4yzM5Kk4a0bADXw5232Ne1WwLuBu1v5MeD6Nn2gzdOWX5MkrfzOqvphVX0HWAKuHEsvJEkjG+ocQJILknwDOAscB74NvFhVL7cqp4FdbXoX8AxAW/4S8KbV5ee5z+rHOpzkZJKTy8vLo/dIkjSUoQKgqn5UVe8AdjP41P62rWpQVd1eVfuqat+OHTu26mEkqXsjXQVUVS8CXwXeCVyYZFtbtBs406bPAJcAtOVvBL6/uvw895EkTdgwVwHtSHJhm/47wHuAJxkEwftbtYPAPW363jZPW/6VqqpWfkO7SuhSYC/w9XF1RJI0mm3rV+Fi4Fi7YuengLuq6r4kTwB3JvlN4BHgjlb/DuCzSZaAcwyu/KGqHk9yF/AE8DJwU1X9aLzdkSQNa90AqKpHgcvPU/4057mKp6r+EvjlNdb1MeBjozdTkjRufhNYkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqXUDIMklSb6a5Ikkjyf5cCu/KMnxJKfa3+2tPEk+lWQpyaNJrli1roOt/qkkB7euW5Kk9QxzBPAy8GtVdRlwNXBTksuAI8CJqtoLnGjzAO8F9rbbYeA2GAQGcAtwFXAlcMtKaGhgz5EvTbsJkjqybgBU1bNV9b/a9P8FngR2AQeAY63aMeD6Nn0A+EwNfA24MMnFwLXA8ao6V1UvAMeB68baG0nS0EY6B5BkD3A58CCws6qebYueA3a26V3AM6vudrqVrVUuSZqCoQMgyU8Dfwj8alX92eplVVVAjaNBSQ4nOZnk5PLy8jhWKUk6j6ECIMlrGLz5f66qvtiKn29DO7S/Z1v5GeCSVXff3crWKv8xVXV7Ve2rqn07duwYpS+SpBEMcxVQgDuAJ6vqt1YtuhdYuZLnIHDPqvIb29VAVwMvtaGiB4D9Sba3k7/7W5kkaQq2DVHnXcA/A76Z5But7N8BHwfuSnII+B7wgbbsfuB9wBLwA+BDAFV1LslHgYdavY9U1bmx9EKSNLJ1A6Cq/geQNRZfc576Bdy0xrqOAkdHaaAkaWv4TWBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkmbANH4N2ACQpCmYhZ9/NwAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQFIXZuHH12aNASBJnTIApBnlJ9bNcfutzwDQ2PnCk+aDASBJnVo3AJIcTXI2yWOryi5KcjzJqfZ3eytPkk8lWUryaJIrVt3nYKt/KsnBremOJGlYwxwB/D5w3avKjgAnqmovcKLNA7wX2Ntuh4HbYBAYwC3AVcCVwC0roaHZ5nBOP9zX/Vk3AKrqvwPnXlV8ADjWpo8B168q/0wNfA24MMnFwLXA8ao6V1UvAMf5yVCRJE3QRs8B7KyqZ9v0c8DONr0LeGZVvdOtbK3yn5DkcJKTSU4uLy9vsHlS3/w0r2Fs+iRwVRVQY2jLyvpur6p9VbVvx44d41qtJOlVNhoAz7ehHdrfs638DHDJqnq7W9la5ZKkKdloANwLrFzJcxC4Z1X5je1qoKuBl9pQ0QPA/iTb28nf/a1M0gSNe2jIoab5NsxloJ8H/ifw1iSnkxwCPg68J8kp4OfbPMD9wNPAEvCfgH8BUFXngI8CD7XbR1qZpAnzTVsrtq1Xoao+uMaia85Tt4Cb1ljPUeDoSK2TNFF7jnyJ7378F6bdjDXNevvmjd8ElqROGQBzysN4SZtlAEhzxOCfT7O63wyAOTSrTyYtFp9ni88A0FzyzWlyFm1bL1p/NsMA0MLa6AvdNwhN2rSecwaA5sasvzFvVftmvd9r2XPkS1va9nnYLuu1cdp9MADGbNo7tFdud60Y13NhWs+pST6uAbBBi/iG8+o+zdILYJS2bKTdWzFctNVHBGutf96em6O2d1b6Nyvt2AwDYIstwpNkq8zatpnF4YpZ20bjtuj9e7Vh+zup7WIAzLmteKJsZp3TeEFP41P4NGzmE/+8boetbve8bpdxMQDmyCI8WRehD7Ogx+04C0NeixZIBsCCGnYcfR5OmE2yjRs9fzCOda9ePok3glkNkWkf0azen7O6jcal+wBY9B28leZp281LWzd6QnStN6x57vdWBuJWrHujRyjT3EfdB8BWGPenh62+nnozpv3i2cy6Z3W947aZq2y28ohoK20kCMf1Rj3tvo/CANiASbyxj/uNb9JPyll9EUxqaGUWT0yP83EneVXTZt54R90P8zCUOU4GwAi28uqYrQqVcY6nTmIsft7HvhfxU+I4jHpUMM6A2ey2noUjmq1iADSTfuMZ9o15lEPZSR7mDnOfzQ6FzdKLbhZCYxaMM7wX6XzFMMs2Um+rdRsA4xoemcdhlo18olnvZOMo61hreiPbcpJvzLPyoh3WpNo7ztfAVn9YGPeQ68praV6fK90GwFpGeXOcl508KbM0prrRI6z16qz1gt9oO2bhObTZT+5b/XiTWte4beX5vXHpJgBmaaOvZ9xtHfeJt2luy1lt17DWOwp69fQsmdV2TcOibItuAmBUaw11zGKqz/OTcRGuiJmVx5qn8xTz/JxdJAsdAKMefm/Vm/s8XNmy1W1chDfBRbLZE/Sj3Nd9MrsWOgDOZ6OXos370MNmLHr/5sGsB7TPkfm0bdIPmOQ64JPABcCnq+rjW/2Y0zhDv9GjiUUcmpA0myZ6BJDkAuA/Au8FLgM+mOSyST3+rL7hzWq7euH2/0lukz5MegjoSmCpqp6uqr8C7gQOTLgNkiQmHwC7gGdWzZ9uZZKkCZv4OYD1JDkMHG6zf57kqU2s7s35BH86hmbNizdDV/0F+9yL7vqcT2yqz/9wmEqTDoAzwCWr5ne3sldU1e3A7eN4sCQnq2rfONY1D3rrL9jnXtjnrTHpIaCHgL1JLk3yWuAG4N4Jt0GSxISPAKrq5ST/EniAwWWgR6vq8Um2QZI0MPFzAFV1P3D/hB5uLENJc6S3/oJ97oV93gKpqq1+DEnSDOrupyAkSQMLGQBJrkvyVJKlJEem3Z5xSXJJkq8meSLJ40k+3MovSnI8yan2d3srT5JPte3waJIrptuDjUlyQZJHktzX5i9N8mDr1xfaBQUkeV2bX2rL90yz3ZuR5MIkdyf5VpInk7yzg/38b9rz+rEkn0/y+kXb10mOJjmb5LFVZSPv1yQHW/1TSQ5utD0LFwDT/rmJLfYy8GtVdRlwNXBT69sR4ERV7QVOtHkYbIO97XYYuG3yTR6LDwNPrpr/BHBrVb0FeAE41MoPAS+08ltbvXn1SeDLVfU24O0M+r+w+znJLuBfA/uq6h8xuEjkBhZvX/8+cN2rykbar0kuAm4BrmLw6wq3rITGyKpqoW7AO4EHVs3fDNw87XZtUV/vAd4DPAVc3MouBp5q078LfHBV/VfqzcuNwXdFTgDvBu4DwuDLMdtevb8ZXF32zja9rdXLtPuwgT6/EfjOq9u+4Pt55VcCLmr77j7g2kXc18Ae4LGN7lfgg8Dvrir/sXqj3BbuCIBOfm6iHfJeDjwI7KyqZ9ui54CdbXoRtsVvA78O/E2bfxPwYlW93OZX9+mV/rblL7X68+ZSYBn4vTb09ekkb2CB93NVnQH+A/AnwLMM9t3DLP6+htH369j29yIGwMJL8tPAHwK/WlV/tnpZDT4SLMSlXUl+EThbVQ9Puy0Ttg24Aritqi4H/oK/HRYAFms/A7QhjAMMwu8fAG/gJ4dKFt6k9+siBsC6Pzcxz5K8hsGb/+eq6out+PkkF7flFwNnW/m8b4t3Ab+U5LsMfjn23QzGxi9MsvIdltV9eqW/bfkbge9PssFjcho4XVUPtvm7GQTCou5ngJ8HvlNVy1X118AXGez/Rd/XMPp+Hdv+XsQAWNifm0gS4A7gyar6rVWL7gVWrgQ4yODcwEr5je1qgquBl1Ydas68qrq5qnZX1R4G+/ErVfUrwFeB97dqr+7vynZ4f6s/d5+Sq+o54Jkkb21F1wBPsKD7ufkT4Ookf7c9z1f6vND7uhl1vz4A7E+yvR057W9lo5v2CZEtOsnyPuD/AN8G/v202zPGfv0cg8PDR4FvtNv7GIx9ngBOAf8NuKjVD4Mror4NfJPBFRZT78cG+/5PgPva9M8AXweWgD8AXtfKX9/ml9ryn5l2uzfR33cAJ9u+/i/A9kXfz8BvAN8CHgM+C7xu0fY18HkG5zj+msGR3qGN7Ffgn7e+LwEf2mh7/CawJHVqEYeAJElDMAAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerU/wOd3xC00XO9GgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((array([2.080e+02, 1.336e+03, 1.500e+01, 1.760e+02, 1.860e+02, 6.300e+01,\n",
       "         2.000e+00, 1.002e+03, 1.720e+02, 1.160e+02, 1.150e+02, 1.550e+02,\n",
       "         1.240e+02, 2.450e+02, 1.510e+02, 1.130e+02, 7.200e+01, 2.420e+02,\n",
       "         3.730e+02, 1.330e+02, 2.000e+01, 1.730e+02, 1.120e+02, 2.190e+02,\n",
       "         1.600e+02, 5.140e+02, 3.010e+02, 8.000e+01, 2.690e+02, 1.720e+02,\n",
       "         3.940e+02, 4.290e+02, 4.330e+02, 2.000e+02, 2.650e+02, 2.860e+02,\n",
       "         2.640e+02, 8.200e+01, 8.700e+01, 3.240e+02, 3.980e+02, 1.490e+02,\n",
       "         1.600e+02, 2.440e+02, 1.980e+02, 2.500e+02, 7.500e+01, 3.400e+02,\n",
       "         5.810e+02, 2.480e+02, 1.380e+02, 1.890e+02, 1.980e+02, 3.900e+02,\n",
       "         3.310e+02, 1.370e+02, 6.230e+02, 2.736e+03, 2.040e+02, 4.960e+02,\n",
       "         4.220e+02, 2.580e+02, 1.640e+02, 1.390e+02, 3.420e+02, 1.300e+02,\n",
       "         3.900e+02, 8.100e+01, 3.560e+02, 1.980e+02, 1.770e+02, 3.550e+02,\n",
       "         2.110e+02, 3.080e+02, 2.470e+02, 3.870e+02, 3.570e+02, 1.590e+02,\n",
       "         5.890e+02, 2.340e+02, 1.880e+02, 2.630e+02, 1.760e+02, 3.540e+02,\n",
       "         1.770e+02, 3.020e+02, 3.320e+02, 4.270e+02, 1.300e+02, 1.760e+02,\n",
       "         4.170e+02, 1.970e+02, 4.200e+02, 4.870e+02, 4.450e+02, 2.970e+02,\n",
       "         1.180e+02, 4.130e+02, 6.220e+02, 1.990e+02, 1.360e+02, 4.010e+02,\n",
       "         2.870e+02, 2.400e+02, 1.020e+02, 3.340e+02, 4.220e+02, 1.680e+02,\n",
       "         4.210e+02, 4.260e+02, 1.590e+02, 5.760e+02, 7.100e+02, 2.110e+02,\n",
       "         1.620e+02, 3.620e+02, 1.400e+02, 1.280e+02, 3.560e+02, 3.320e+02,\n",
       "         1.670e+02, 3.370e+02, 3.220e+02, 8.600e+01, 1.140e+02, 4.580e+02,\n",
       "         1.480e+02, 1.140e+02, 4.930e+02, 2.960e+02, 3.590e+02, 3.270e+02,\n",
       "         4.000e+01, 1.640e+02, 3.910e+02, 4.040e+02, 2.530e+02, 3.700e+02,\n",
       "         1.271e+03, 1.510e+02, 1.370e+02, 9.700e+01, 8.200e+01, 2.460e+02,\n",
       "         3.610e+02, 5.160e+02, 4.420e+02, 2.091e+03, 3.820e+02, 2.890e+02,\n",
       "         9.900e+01, 3.190e+02, 4.160e+02, 3.620e+02, 2.220e+02, 1.060e+02,\n",
       "         2.970e+02, 3.960e+02, 3.100e+02, 2.110e+02, 3.200e+02, 2.800e+02,\n",
       "         9.600e+01, 3.990e+02, 3.290e+02, 5.130e+02, 2.000e+02, 4.140e+02,\n",
       "         3.270e+02, 3.850e+02, 4.240e+02, 6.650e+02, 2.460e+02, 4.980e+02,\n",
       "         6.820e+02, 4.310e+02, 4.370e+02, 3.300e+02, 1.280e+02, 2.120e+02,\n",
       "         7.420e+02, 3.400e+02, 7.340e+02, 7.940e+02, 1.380e+02, 1.930e+02,\n",
       "         5.610e+02, 2.780e+02, 3.640e+02, 2.100e+02, 5.380e+02, 1.900e+02,\n",
       "         3.190e+02, 2.060e+02, 3.710e+02, 5.110e+02, 1.800e+02, 4.930e+02,\n",
       "         4.670e+02, 4.760e+02, 3.130e+02, 5.710e+02, 4.140e+02, 3.640e+02,\n",
       "         5.260e+02, 5.960e+02, 3.480e+02, 4.560e+02, 2.370e+02, 1.990e+02,\n",
       "         4.760e+02, 3.910e+02, 3.880e+02, 3.690e+02, 6.880e+02, 1.740e+02,\n",
       "         3.580e+02, 1.800e+02, 2.830e+02, 2.300e+02, 1.630e+02, 1.260e+02,\n",
       "         8.030e+02, 3.900e+02, 3.190e+02, 9.300e+01, 4.860e+02, 5.130e+02,\n",
       "         2.570e+02, 3.350e+02, 1.600e+02, 5.790e+02, 1.930e+02, 3.010e+02,\n",
       "         3.830e+02, 4.780e+02, 2.930e+02, 3.260e+02, 4.940e+02, 1.170e+02,\n",
       "         2.530e+02, 3.600e+02, 4.660e+02, 6.640e+02, 4.290e+02, 6.790e+02,\n",
       "         3.670e+02, 3.380e+02, 2.750e+02, 1.810e+02, 2.420e+02, 2.020e+02,\n",
       "         5.770e+02, 2.090e+02, 4.960e+02, 3.050e+02, 3.090e+02, 3.050e+02,\n",
       "         1.710e+02, 5.330e+02, 4.350e+02, 4.820e+02, 2.380e+02, 5.180e+02,\n",
       "         1.160e+02, 5.780e+02, 2.190e+02, 2.470e+02, 4.190e+02, 1.070e+03,\n",
       "         3.740e+02, 2.700e+02, 1.490e+02, 3.960e+02, 2.640e+02, 2.780e+02,\n",
       "         5.720e+02, 8.790e+02, 2.310e+02, 3.670e+02, 2.900e+02, 3.730e+02,\n",
       "         3.070e+02, 4.320e+02, 3.570e+02, 2.430e+02, 3.770e+02, 4.510e+02,\n",
       "         3.000e+02, 2.000e+02, 2.980e+02, 6.920e+02, 4.300e+02, 1.890e+02,\n",
       "         4.070e+02, 4.210e+02, 3.410e+02, 2.940e+02, 3.170e+02, 3.730e+02,\n",
       "         1.130e+02, 4.810e+02, 4.580e+02, 2.960e+02, 5.650e+02, 2.730e+02,\n",
       "         2.110e+02, 4.710e+02, 5.230e+02, 2.800e+02, 1.440e+02, 1.144e+03,\n",
       "         4.180e+02, 2.310e+02, 1.049e+03, 3.940e+02, 1.239e+03, 1.179e+03,\n",
       "         3.320e+02, 3.890e+02, 2.240e+02, 2.700e+02, 4.550e+02, 3.430e+02,\n",
       "         2.900e+02, 3.350e+02, 1.310e+02, 2.740e+02, 1.820e+02, 4.010e+02,\n",
       "         2.020e+02, 2.890e+02, 2.660e+02, 5.810e+02, 4.950e+02, 1.790e+02,\n",
       "         4.990e+02, 2.100e+02, 3.400e+02, 6.370e+02, 1.576e+03, 2.890e+02,\n",
       "         3.190e+02, 7.200e+01, 5.480e+02, 3.320e+02, 4.980e+02, 6.330e+02,\n",
       "         1.890e+02, 2.400e+02, 2.850e+02, 3.050e+02, 2.520e+02, 6.020e+02,\n",
       "         4.070e+02, 3.470e+02, 2.570e+02, 2.830e+02, 7.150e+02, 4.670e+02,\n",
       "         1.393e+03, 3.530e+02, 3.720e+02, 5.750e+02, 5.920e+02, 3.760e+02,\n",
       "         2.430e+02, 2.900e+02, 6.370e+02, 6.830e+02, 1.830e+02, 3.330e+02,\n",
       "         3.680e+02, 3.190e+02, 4.250e+02, 5.330e+02, 3.990e+02, 4.570e+02,\n",
       "         6.050e+02, 6.510e+02, 5.850e+02, 3.740e+02, 1.159e+03, 6.300e+02,\n",
       "         6.430e+02, 3.280e+02, 4.560e+02, 2.360e+02, 3.290e+02, 5.290e+02,\n",
       "         6.185e+03, 2.630e+02, 2.430e+02, 1.190e+02, 7.030e+02, 8.320e+02,\n",
       "         2.400e+02, 2.760e+02, 4.290e+02, 3.860e+02, 2.810e+02, 3.030e+02,\n",
       "         1.314e+03, 5.410e+02, 1.520e+03, 4.000e+02, 2.360e+02, 6.130e+02,\n",
       "         4.850e+02, 2.810e+02, 2.240e+02, 3.350e+02, 2.550e+02, 1.660e+02,\n",
       "         9.370e+02, 2.970e+02, 3.940e+02, 5.910e+02, 5.110e+02, 2.720e+02,\n",
       "         2.570e+02, 1.710e+02, 3.910e+02, 6.810e+02, 4.160e+02, 2.000e+02,\n",
       "         5.290e+02, 6.890e+02, 2.210e+02, 7.500e+02, 4.140e+02, 2.060e+02,\n",
       "         1.296e+03, 4.350e+02, 3.910e+02, 4.020e+02, 4.780e+02, 5.640e+02,\n",
       "         2.500e+02, 1.410e+02, 3.940e+02, 2.300e+02, 2.060e+02, 3.560e+02,\n",
       "         4.290e+02, 2.420e+02, 1.940e+02, 2.880e+02, 4.620e+02, 2.760e+02,\n",
       "         1.873e+03, 5.800e+02, 4.480e+02, 2.740e+02, 1.660e+02, 1.084e+03,\n",
       "         9.300e+01, 3.440e+02, 7.320e+02, 6.050e+02, 3.130e+02, 2.460e+02,\n",
       "         3.570e+02, 5.670e+02, 3.600e+02, 6.030e+02, 4.730e+02, 3.350e+02,\n",
       "         4.310e+02, 6.890e+02, 7.280e+02, 3.720e+02, 3.588e+03, 3.770e+02,\n",
       "         6.160e+02, 4.610e+02, 2.940e+02, 4.220e+02, 5.500e+02, 2.670e+02,\n",
       "         7.660e+02, 5.290e+02, 2.740e+02, 6.660e+02, 3.550e+02, 2.720e+02,\n",
       "         3.250e+02, 2.240e+02, 4.300e+02, 2.960e+02, 6.520e+02, 4.510e+02,\n",
       "         2.680e+02, 1.970e+02, 2.210e+02, 2.570e+02, 4.690e+02, 3.310e+02,\n",
       "         2.400e+02, 2.560e+02, 4.510e+02, 2.960e+02, 4.230e+02, 4.740e+02,\n",
       "         4.320e+02, 5.820e+02, 6.460e+02, 3.110e+02, 3.050e+02, 4.680e+02,\n",
       "         1.780e+02, 3.290e+02, 4.710e+02, 2.010e+02, 2.500e+02, 6.490e+02,\n",
       "         3.240e+02, 2.380e+02, 3.670e+02, 2.440e+02, 3.770e+02, 1.180e+02,\n",
       "         3.940e+02, 2.250e+02, 4.170e+02, 3.940e+02, 2.100e+02, 2.760e+02,\n",
       "         5.880e+02, 5.910e+02, 3.020e+02, 3.530e+02, 2.590e+02, 3.930e+02,\n",
       "         6.840e+02, 1.940e+02, 8.460e+02, 8.650e+02, 5.530e+02, 2.420e+02,\n",
       "         2.480e+02, 4.630e+02, 4.000e+02, 2.060e+02, 1.720e+02, 2.230e+02,\n",
       "         4.410e+02, 5.420e+02, 3.850e+02, 2.670e+02, 3.450e+02, 3.530e+02,\n",
       "         1.182e+03, 3.470e+02, 6.190e+02, 2.220e+02, 2.414e+03, 4.140e+02,\n",
       "         2.540e+02, 1.760e+02, 1.360e+02, 3.100e+02, 4.560e+02, 3.110e+02,\n",
       "         2.400e+02, 5.860e+02, 4.200e+02, 2.540e+02, 4.590e+02, 4.020e+02,\n",
       "         3.690e+02, 4.370e+02, 5.840e+02, 5.090e+02, 2.380e+02, 2.120e+02,\n",
       "         3.330e+02, 7.600e+02, 4.810e+02, 3.020e+02, 5.410e+02, 1.176e+03,\n",
       "         1.990e+02, 7.370e+02, 5.470e+02, 5.090e+02, 6.540e+02, 6.630e+02,\n",
       "         3.490e+02, 4.710e+02, 4.980e+02, 1.440e+02, 3.490e+02, 3.350e+02,\n",
       "         5.170e+02, 1.407e+03, 6.500e+02, 7.750e+02, 4.060e+02, 6.240e+02,\n",
       "         4.490e+02, 6.060e+02, 3.090e+02, 4.350e+02, 4.900e+02, 3.500e+02,\n",
       "         6.260e+02, 5.960e+02, 3.210e+02, 5.310e+02, 4.400e+02, 1.990e+02,\n",
       "         5.920e+02, 1.150e+02, 5.310e+02, 2.260e+02, 3.960e+02, 4.550e+02,\n",
       "         4.800e+02, 3.880e+02, 2.160e+02, 6.110e+02, 3.580e+02, 4.150e+02,\n",
       "         4.440e+02, 7.580e+02, 4.530e+02, 5.840e+02, 1.436e+03, 4.880e+02,\n",
       "         9.980e+02, 1.790e+02, 2.760e+02, 3.060e+02, 2.840e+02, 3.050e+02,\n",
       "         4.220e+02, 4.340e+02, 2.920e+02, 4.320e+02, 4.140e+02, 7.700e+02,\n",
       "         8.390e+02, 5.210e+02, 3.980e+02, 6.050e+02, 1.040e+02, 3.680e+02,\n",
       "         3.630e+02, 7.640e+02, 9.210e+02, 3.790e+02, 2.740e+02, 8.970e+02,\n",
       "         4.230e+02, 3.510e+02, 1.860e+02, 2.380e+02, 5.130e+02, 4.280e+02,\n",
       "         4.860e+02, 3.020e+02, 2.700e+02, 1.830e+02, 7.350e+02, 3.610e+02,\n",
       "         2.660e+02, 7.930e+02, 4.400e+02, 1.350e+03, 1.490e+02, 3.470e+03,\n",
       "         4.350e+02, 1.071e+03, 4.730e+02, 5.230e+02, 8.630e+02, 5.200e+02,\n",
       "         1.200e+02, 4.260e+02, 5.350e+02, 3.720e+02, 1.650e+02, 8.900e+01,\n",
       "         7.040e+02, 3.240e+02, 7.280e+02, 1.640e+02, 4.370e+02, 4.220e+02,\n",
       "         2.860e+02, 3.680e+02, 4.020e+02, 7.140e+02, 2.730e+02, 4.140e+02,\n",
       "         2.060e+02, 3.450e+02, 3.130e+02, 2.410e+02, 2.600e+02, 4.850e+02,\n",
       "         3.200e+02, 6.650e+02, 2.960e+02, 1.550e+02, 2.540e+02, 6.820e+02,\n",
       "         2.870e+02, 3.880e+02, 3.570e+02, 8.060e+02, 1.660e+02, 3.960e+02,\n",
       "         2.810e+02, 3.430e+02, 9.110e+02, 3.850e+02, 3.650e+02, 3.070e+02,\n",
       "         2.880e+02, 4.390e+02, 1.580e+02, 8.230e+02, 5.020e+02, 3.220e+02,\n",
       "         2.970e+02, 3.190e+02, 4.110e+02, 2.810e+02, 1.496e+03, 2.740e+02,\n",
       "         4.000e+02, 1.992e+03, 5.710e+02, 4.040e+02, 2.370e+02, 4.790e+02,\n",
       "         6.270e+02, 6.600e+02, 3.470e+02, 4.990e+02, 6.400e+02, 3.440e+02,\n",
       "         5.060e+02, 1.610e+02, 4.050e+02, 6.210e+02, 3.460e+02, 2.900e+02,\n",
       "         8.430e+02, 4.250e+02, 3.490e+02, 4.710e+02, 4.710e+02, 3.690e+02,\n",
       "         5.330e+02, 4.190e+02, 2.680e+02, 5.330e+02, 5.700e+02, 2.660e+02,\n",
       "         1.980e+02, 6.770e+02, 4.430e+02, 3.090e+02, 3.010e+02, 8.820e+02,\n",
       "         5.710e+02, 2.280e+02, 2.970e+02, 6.010e+02, 4.210e+02, 5.180e+02,\n",
       "         3.070e+02, 4.410e+02, 4.480e+02, 5.340e+02, 3.160e+02, 4.680e+02,\n",
       "         7.200e+02, 3.000e+02, 2.680e+02, 8.260e+02, 3.200e+02, 4.830e+02,\n",
       "         3.470e+02, 4.390e+02, 3.660e+02, 4.530e+02, 2.700e+02, 4.380e+02,\n",
       "         4.420e+02, 4.360e+02, 5.290e+02, 4.090e+02, 4.940e+02, 2.970e+02,\n",
       "         3.740e+02, 4.680e+02, 5.610e+02, 4.550e+02, 3.300e+02, 1.311e+03,\n",
       "         5.030e+02, 3.430e+02, 4.630e+02, 3.720e+02, 8.690e+02, 6.510e+02,\n",
       "         2.310e+02, 5.970e+02, 4.370e+02, 2.500e+02, 4.830e+02, 3.680e+02,\n",
       "         1.750e+02, 6.380e+02, 1.830e+02, 5.050e+02, 1.684e+03, 2.650e+02,\n",
       "         8.140e+02, 2.800e+02, 5.130e+02, 2.030e+02, 3.430e+02, 2.970e+02,\n",
       "         4.460e+02, 5.210e+02, 3.430e+02, 3.840e+02, 4.960e+02, 8.300e+02,\n",
       "         3.640e+02, 6.440e+02, 2.550e+02, 6.330e+02, 3.550e+02, 2.900e+02,\n",
       "         4.040e+02, 2.500e+02, 4.950e+02, 1.780e+02, 1.192e+03, 7.470e+02,\n",
       "         4.040e+02, 3.700e+02, 6.020e+02, 3.340e+02, 3.430e+02, 3.360e+02,\n",
       "         5.780e+02, 3.600e+02, 4.150e+02, 4.500e+02, 3.380e+02, 1.249e+03,\n",
       "         3.200e+02, 6.830e+02, 3.070e+02, 4.550e+02, 3.490e+02, 7.060e+02,\n",
       "         6.920e+02, 5.020e+02, 2.610e+02, 4.360e+02, 1.980e+02, 4.410e+02,\n",
       "         3.970e+02, 4.520e+02, 9.250e+02, 5.260e+02, 6.010e+02, 7.300e+02,\n",
       "         5.780e+02, 4.440e+02, 4.470e+02, 5.160e+02, 2.930e+02, 3.120e+02,\n",
       "         6.470e+02, 4.050e+02, 4.270e+02, 2.900e+02, 3.800e+02, 2.640e+02,\n",
       "         2.430e+02, 6.380e+02, 4.650e+02, 3.770e+02, 3.730e+02, 4.590e+02,\n",
       "         3.530e+02, 6.440e+02, 6.330e+02, 4.130e+02, 1.680e+02, 3.200e+02,\n",
       "         4.640e+02, 6.980e+02, 3.240e+02, 3.410e+02, 1.260e+02, 2.420e+02,\n",
       "         3.520e+02, 3.480e+02, 2.500e+02, 4.090e+02, 2.740e+02, 7.250e+02,\n",
       "         5.190e+02, 5.160e+02, 4.670e+02, 5.280e+02, 3.150e+02, 4.770e+02,\n",
       "         6.840e+02, 2.460e+02, 3.900e+02, 3.170e+02, 6.510e+02, 5.780e+02,\n",
       "         3.210e+02, 3.970e+02, 2.860e+02, 2.560e+02, 2.550e+02, 3.050e+02,\n",
       "         5.840e+02, 3.110e+02, 2.890e+02, 6.200e+02, 6.770e+02, 4.470e+02,\n",
       "         4.400e+02, 5.050e+02, 2.930e+02, 3.260e+02, 1.370e+03, 3.280e+02,\n",
       "         4.110e+02, 4.597e+03, 1.630e+02, 3.040e+02, 2.790e+02, 2.870e+02,\n",
       "         3.030e+02, 2.750e+02, 2.400e+02, 2.690e+02, 6.540e+02, 4.160e+02,\n",
       "         2.330e+02, 4.310e+02, 3.560e+02, 2.160e+02, 5.890e+02, 7.790e+02,\n",
       "         4.450e+02, 4.230e+02, 3.940e+02, 4.510e+02, 1.950e+02, 5.490e+02,\n",
       "         4.030e+02, 4.350e+02, 5.910e+02, 2.490e+02, 5.240e+02, 1.257e+03,\n",
       "         3.370e+02, 5.210e+02, 3.990e+02, 1.644e+03, 3.730e+02, 4.980e+02,\n",
       "         6.540e+02, 3.330e+02, 3.610e+02, 4.930e+02, 4.330e+02, 3.910e+02,\n",
       "         4.460e+02, 6.910e+02, 5.580e+02, 4.070e+02, 1.657e+03, 6.080e+02,\n",
       "         5.830e+02, 4.510e+02, 5.070e+02, 7.610e+02, 4.370e+02, 6.070e+02,\n",
       "         4.980e+02, 2.000e+02, 5.530e+02, 2.650e+02]),\n",
       "  array([  0.   ,   0.999,   1.998, ..., 997.002, 998.001, 999.   ]),\n",
       "  <a list of 1000 Patch objects>),\n",
       " None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(labels, bins=1000),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels with extremely high occurances should be investigated. Feature reduction should take the most dog and cat features that are most common to each target and most dissimiliar to other targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in previously computed cluster data for dogs\n",
    "dog_centers = np.load('20190120-kmeans-samplecenters-dogs.npy')\n",
    "dog_labels = np.load('20190120-kmeans-samplelabels-dogs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 500 most frequent dog labels & their centers\n",
    "ddf = pd.DataFrame(labels, columns=[\"desc_dogs\"])\n",
    "top_500_ix = ddf[\"desc_dogs\"].value_counts().nlargest(500).reset_index()['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter descriptors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I opted to reduce the labels to the 500 most frequent labels. This is just a starting place; more work will need to continue here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    620\n",
       "1    702\n",
       "2     40\n",
       "3    649\n",
       "4     52\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_500_ix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_ix = np.where(np.in1d(dog_labels, top_500_ix))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216798, 128)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_desc[desc_ix].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_filter = dog_desc[desc_ix]\n",
    "lab_filter = dog_labels[desc_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_fiter = dog_centers[top_500_ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels for other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed cat descriptors\n",
    "cat_descriptors = np.load('20190120-sampledesc-cats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(desc, centers, labels):\n",
    "    pred_label = np.empty(0)\n",
    "    pred_dist = np.empty(0)\n",
    "    for d in desc:\n",
    "        min_distance = None\n",
    "        min_lab = None\n",
    "        for lab in labels:\n",
    "            current_distance = np.linalg.norm(d - centers[lab])\n",
    "            if min_distance is None:\n",
    "                min_distance = current_distance\n",
    "                min_label = current_label\n",
    "            if current_distance < min_distance:\n",
    "                min_distance = current_distance\n",
    "                min_label = current_label\n",
    "                \n",
    "        # Store all predicted labels in 1-d array\n",
    "        pred_label = np.append(pred_label, min_label)\n",
    "        pred_dist = np.append(pred_dist, min_dist)\n",
    "    \n",
    "    return pred_label, pred_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-e3a9b8d7dcf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_descriptors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdog_centers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_500_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-267-d457e808a731>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(desc, centers, labels)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmin_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mcurrent_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_distance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mmin_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py3cv4/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2358\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cat_pred, pred_dist = predict(cat_descriptors, dog_centers, top_500_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Dataset\n",
    "For each image we will need to get the pre-comupted descriptors and use the cluster centers to determine best label for each label. The input to a function should be an image number to query the descriptors and the function will translate the image to a 1-d vector with counts for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(cluster_label, image, desc, centers):\n",
    "    unique_labels = np.unique(cluster_label)\n",
    "    unique_labels = np.sort(unique_labels, axis=None)\n",
    "    unique_images = np.unique(image)\n",
    "    \n",
    "    for img in unique_images:\n",
    "        index = np.where(np.in1d(image, img))[0]\n",
    "        img_descriptors = desc[index]\n",
    "        \n",
    "        img_label = np.empty(0)  \n",
    "        #img_label_count = np.empty(0)\n",
    "        \n",
    "        for d in img_descriptors:\n",
    "            min_distance = None\n",
    "            min_lab = None\n",
    "            for lab in unique_labels:\n",
    "                current_distance = np.linalg.norm(d - dog_centers[lab])\n",
    "                if min_distance is None:\n",
    "                    min_distance = current_distance\n",
    "                    min_label = current_label\n",
    "                if current_distance < min_distance:\n",
    "                    min_distance = current_distance\n",
    "                    min_label = current_label\n",
    "            \n",
    "            # Store all predicted labels in 1-d array\n",
    "            img_label = np.append(img_label, min_label)\n",
    "        \n",
    "        # Group by\n",
    "        #img_label = pd.Series(img_label)\n",
    "        #img_label_counts = img_label.value_counts()\n",
    "        # Left join to labels to generate 'zero' columns\n",
    "        \n",
    "        # Transpose\n",
    "        # Insert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436862"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dog_labels)\n",
    "#add_row(dog_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ravel(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620    4797\n",
       "702    3620\n",
       "40     2409\n",
       "649    2353\n",
       "52     2318\n",
       "304    2292\n",
       "584    2224\n",
       "61     2016\n",
       "83     1902\n",
       "266    1883\n",
       "212    1635\n",
       "427    1615\n",
       "371    1510\n",
       "845    1482\n",
       "837    1421\n",
       "763    1326\n",
       "286    1303\n",
       "81     1135\n",
       "637    1104\n",
       "484    1076\n",
       "744    1052\n",
       "395    1043\n",
       "724    1037\n",
       "532    1031\n",
       "194     992\n",
       "440     990\n",
       "678     990\n",
       "617     984\n",
       "331     967\n",
       "198     938\n",
       "       ... \n",
       "197      93\n",
       "211      93\n",
       "109      92\n",
       "66       90\n",
       "86       89\n",
       "216      84\n",
       "169      81\n",
       "43       81\n",
       "185      80\n",
       "607      79\n",
       "137      78\n",
       "27       75\n",
       "118      69\n",
       "334      68\n",
       "437      65\n",
       "135      65\n",
       "11       60\n",
       "193      60\n",
       "120      60\n",
       "78       46\n",
       "295      43\n",
       "441      28\n",
       "30       18\n",
       "10       14\n",
       "3        13\n",
       "399      10\n",
       "7         6\n",
       "8         5\n",
       "1         1\n",
       "103       1\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labs = None\n",
    "\n",
    "for img in np.unique(dog_img):\n",
    "    \n",
    "    index = np.where(np.in1d(dog_img, img))[0]\n",
    "    d = dog_desc[index]\n",
    "    num_desc = d.shape[0]\n",
    "    labs = np.empty(0)\n",
    "    \n",
    "    min_distance = None\n",
    "    min_lab = None\n",
    "    \n",
    "    for descriptor in d:\n",
    "        \n",
    "        for current_label in range(0,999):\n",
    "            current_distance = np.linalg.norm(descriptor - dog_centers[current_label])\n",
    "\n",
    "            if min_distance is None:\n",
    "                min_distance = current_distance\n",
    "                min_label = current_label\n",
    "            if current_distance < min_distance:\n",
    "                min_distance = current_distance\n",
    "                min_label = current_label\n",
    "        \n",
    "        labs = np.append(labs, min_label)\n",
    "        #transpose, fill with zeros for missing labels\n",
    "        # write to pandas dataframe row\n",
    "        \n",
    "    ## function ##\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through new descriptors and assign labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.empty(0)\n",
    "predicted_distance = np.empty(0)\n",
    "\n",
    "for desc in desc_total[0:3]:\n",
    "    \n",
    "    min_distance = None\n",
    "    min_label = None\n",
    "    current_distance = None\n",
    "    current_label = None\n",
    "\n",
    "    for lab in range(0,999):\n",
    "        \n",
    "        current_distance = np.linalg.norm(cent - x)\n",
    "        dist(desc, centers[lab])\n",
    "        \n",
    "        if min_distance is None:\n",
    "            min_distance = current_distance\n",
    "            min_label = lab\n",
    "        if current_distance < min_distance:\n",
    "            min_distance = current_distance\n",
    "            min_label = lab\n",
    "            \n",
    "    predicted_labels = np.append(predicted_labels, min_label)\n",
    "    predicted_distance = np.append(predicted_distance, min_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([124.51062012, 200.84196472, 119.63799286])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining Tasks\n",
    "\n",
    "- Use %%timeit\n",
    "- Try with 5000 photos of each target, decrease as needed\n",
    "- Test on 500/each\n",
    "- Create SIFT features on entire set\n",
    "- Cluster on training set\n",
    "- Create dictionary\n",
    "- Transform to dictionary feature set\n",
    "- SVM on dictionary transform\n",
    "- Transform testing set to dictionary\n",
    "- Predict w/ trained SVM\n",
    "\n",
    "## Packages Needed:\n",
    "- **pandas** for using scikit\n",
    "- **scikit-learn** for kmeans & SVM\n",
    "\n",
    "## DAN2 Research:\n",
    "- How can we reduce the dictionary?\n",
    "- Should we pre-process images more than grey-scaling? (e.g., HOG, edge detectiony, feature detection)\n",
    "    - explore opencv4 for latest offerings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addtional Info\n",
    "http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

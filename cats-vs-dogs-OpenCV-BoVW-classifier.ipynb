{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook builds up a linear classifier of the cats & dogs image dataset from Kaggle. The images are first decomposed into keypoints via OpenCV's SIFT algorithm. The data from each keypoint is used to build a model (bag of visual words) that describes each image. The bag of visual words is then run through a linear classifier to determine whether each image is a cat or a dog. The model acheives roughly 73% accuracy when training on 5000 images and testing on 1000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import cv2\n",
    "import io\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker import get_execution_role\n",
    "from scipy.spatial.distance import cdist\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile('train.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [x for x in archive.namelist() if re.match('train.*jpg', x) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = archive.read('train/dog.9455.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imdecode(np.frombuffer(img_data, np.uint8), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sift(gray_img):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, desc = sift.detectAndCompute(gray_img, None)\n",
    "    return kp, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_desc(file):\n",
    "    buf = archive.read(file)\n",
    "    img = cv2.imdecode(np.frombuffer(buf, np.uint8), 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    kp, desc = generate_sift(img)\n",
    "    \n",
    "    num_desc = desc.shape[0]\n",
    "    images = np.full((num_desc,1), file)\n",
    "    \n",
    "    return images, kp, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extract(file_list):\n",
    "    \n",
    "    num_of_files = len(file_list)\n",
    "    i = 1\n",
    "    desc_total = None\n",
    "    kp_total = None\n",
    "    img_total = None\n",
    "    \n",
    "    for file in file_list:\n",
    "        \n",
    "        # Extract all SIFT keypoints and descriptors\n",
    "        images, kp, desc = extract_desc(file)\n",
    "        \n",
    "        if i == 1:\n",
    "            kp_total = kp\n",
    "            desc_total = desc\n",
    "            img_total = images\n",
    "            clear_output(wait=True)\n",
    "            print(i, \"/\", num_of_files, \"completed\")\n",
    "            i = i + 1\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            kp_total = np.append(kp_total, kp)\n",
    "            desc_total = np.vstack((desc_total, desc))\n",
    "            img_total = np.vstack((img_total, images))\n",
    "            clear_output(wait=True)\n",
    "            print(i, \"/\", num_of_files, \"completed\")\n",
    "            i = i + 1\n",
    "    \n",
    "    \n",
    "    #return img_total, kp_total, desc_total\n",
    "    return desc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_descriptors(file):\n",
    "    # Read in file\n",
    "    buf = archive.read(file)\n",
    "    img = cv2.imdecode(np.frombuffer(buf, np.uint8), 1)\n",
    "    \n",
    "    # Convert to greyscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract keypoints and SIFT descriptors\n",
    "    kp, desc = generate_sift(img)\n",
    "    \n",
    "    # Prep keypoints\n",
    "    points = []\n",
    "    for k, d in zip(kp, desc):\n",
    "        point = (k.angle, k.class_id, k.convert, k.octave, k.overlap, k.pt, k.response, k.size, d)\n",
    "        points.append(point)\n",
    "    \n",
    "    # Save to dictionary object\n",
    "    output = {}\n",
    "    output['filename'] = file\n",
    "    output['kpd'] = points\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "for k, d in zip(kp, desc):\n",
    "    point = (k.angle, k.class_id, k.convert, k.octave, k.overlap, k.pt, k.response, k.size, desc)\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('train-descriptors'):\n",
    "    os.makedirs('train-descriptors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = extract_descriptors(f)\n",
    "save_name = output['filename'].split('/')[1]\n",
    "file = open('train-descriptors/' + save_name + '.P', 'wb')\n",
    "pickle.dump(output, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Keypoint Descriptors from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_files = len(train_files)\n",
    "i = 1\n",
    "for f in train_files:\n",
    "    output = extract_descriptors(f)\n",
    "    save_name = output['filename'].split('/')[1]\n",
    "    file = open('train-descriptors/' + save_name + '.P', 'wb')\n",
    "    pickle.dump(output, file)\n",
    "    clear_output(wait=True)\n",
    "    print(i, \"/\", num_of_files, \"completed\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = os.listdir('train-descriptors/')[:5000]\n",
    "dogs = [f for f in ft if f.find('dog') != -1]\n",
    "cats = [f for f in ft if f.find('cat') != -1]\n",
    "\n",
    "prefix = 'train-descriptors/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append all descriptors into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = None\n",
    "i = 0\n",
    "for file in dogs:\n",
    "    i += 1   \n",
    "    f = 'train-descriptors/' + file\n",
    "    with open(f, 'rb') as pf:\n",
    "        a = pickle.load(pf)\n",
    "        desc = [x[8] for x in a['kpd']]\n",
    "        if descriptors is None:\n",
    "            descriptors = desc\n",
    "        else: descriptors = np.vstack((descriptors, desc))\n",
    "            \n",
    "    clear_output(wait=True)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358960\n"
     ]
    }
   ],
   "source": [
    "print(sys.getsizeof(descriptors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('train-descriptors.P', 'wb')\n",
    "pickle.dump(descriptors, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptors for 2500 dog images, appended into one file is roughly 1.1 GB in size. This was uploaded via web browser to S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_s3_data(bucket, prefix, channel, X):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(buf, X.astype('float32'))\n",
    "    buf.seek(0)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, channel + '.data')).upload_fileobj(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket\n",
    "bucket = 'catsvsdogs-ml'\n",
    "prefix = 'sagemaker/DEMO-kmeans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_s3_data(bucket, prefix, 'train', descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Sagemaker Experiments to choose K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'arn:aws:iam::536197384257:role/service-role/AmazonSageMaker-ExecutionRole-20190129T171919'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_time = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_folder = 'kmeans-lowlevel-' + output_time\n",
    "K = range(50, 550, 50) # change the range to be used for k\n",
    "#K = [500]\n",
    "INSTANCE_COUNT = 1\n",
    "run_parallel_jobs = False #make this false to run jobs one at a time, especially if you do not want \n",
    "#create too many EC2 instances at once to avoid hitting into limits.\n",
    "job_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = get_image_uri(boto3.Session().region_name, 'kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train job:50\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:100\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:150\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:200\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:250\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:300\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:350\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:400\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:450\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "starting train job:500\n",
      "training artifacts will be uploaded to: s3://catsvsdogs-ml/kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39\n",
      "InProgress\n",
      "Training job ended with status: Completed\n"
     ]
    }
   ],
   "source": [
    "# launching jobs for all k\n",
    "for k in K:\n",
    "    print('starting train job:' + str(k))\n",
    "    output_location = 's3://{}/kmeans_example/output/'.format(bucket) + output_folder\n",
    "    print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "    job_name = output_folder + str(k)\n",
    "\n",
    "    create_training_params = \\\n",
    "    {\n",
    "        \"AlgorithmSpecification\": {\n",
    "            \"TrainingImage\": image,\n",
    "            \"TrainingInputMode\": \"File\"\n",
    "        },\n",
    "        \"RoleArn\": role,\n",
    "        \"OutputDataConfig\": {\n",
    "            \"S3OutputPath\": output_location\n",
    "        },\n",
    "        \"ResourceConfig\": {\n",
    "            \"InstanceCount\": INSTANCE_COUNT,\n",
    "            \"InstanceType\": \"ml.c4.8xlarge\",\n",
    "            \"VolumeSizeInGB\": 50\n",
    "        },\n",
    "        \"TrainingJobName\": job_name,\n",
    "        \"HyperParameters\": {\n",
    "            \"k\": str(k),\n",
    "            \"feature_dim\": \"128\",\n",
    "            \"mini_batch_size\": \"1000\"\n",
    "        },\n",
    "        \"StoppingCondition\": {\n",
    "            \"MaxRuntimeInSeconds\": 60 * 60\n",
    "        },\n",
    "            \"InputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelName\": \"train\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": \"s3://{}/{}/train.data\".format(bucket, prefix),\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                    }\n",
    "                },\n",
    "\n",
    "                \"CompressionType\": \"None\",\n",
    "                \"RecordWrapperType\": \"None\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "    sagemaker.create_training_job(**create_training_params)\n",
    "\n",
    "    status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)\n",
    "    if not run_parallel_jobs:\n",
    "        try:\n",
    "            sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "        finally:\n",
    "            status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "            print(\"Training job ended with status: \" + status)\n",
    "            if status == 'Failed':\n",
    "                message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "                print('Training failed with the following error: {}'.format(message))\n",
    "                raise Exception('Training job failed')\n",
    "    \n",
    "    job_names.append(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to check training job status\n",
    "response = sagemaker.describe_training_job(\n",
    "    TrainingJobName='kmeans-lowlevel-2019-03-18-06-32-52500'\n",
    ")\n",
    "#response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catsvsdogs-ml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for k=50 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-3950/output/model.tar.gz)\n",
      "x model_algo-1\n",
      "x state_f13371e0-e162-4257-adb8-6321bc88114a\n",
      "Model for k=100 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39100/output/model.tar.gz)\n",
      "x state_932e0871-64fa-4f53-964e-2ce777498451\n",
      "x model_algo-1\n",
      "Model for k=150 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39150/output/model.tar.gz)\n",
      "x model_algo-1\n",
      "x state_795a0e09-e2b5-4209-ac0c-d2bf43c62eb4\n",
      "Model for k=200 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39200/output/model.tar.gz)\n",
      "x model_algo-1\n",
      "x state_3704a49e-1047-447b-80a1-c777ed53a2f6\n",
      "Model for k=250 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39250/output/model.tar.gz)\n",
      "x model_algo-1\n",
      "x state_b3079804-e29d-4958-936e-f75b49bdbcc5\n",
      "Model for k=300 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39300/output/model.tar.gz)\n",
      "x state_c5726545-cf1b-4569-92be-c381c0b13986\n",
      "x model_algo-1\n",
      "Model for k=350 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39350/output/model.tar.gz)\n",
      "x model_algo-1\n",
      "x state_9194ac54-b6b6-4880-8d49-5c546157fcea\n",
      "Model for k=400 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39400/output/model.tar.gz)\n",
      "x state_3cdc6008-628f-4d43-9896-2a898f2cacdf\n",
      "x model_algo-1\n",
      "Model for k=450 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39450/output/model.tar.gz)\n",
      "x state_24592ebd-111a-4568-ba09-d710917f93eb\n",
      "x model_algo-1\n",
      "Model for k=500 (kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/kmeans-lowlevel-2019-03-18-07-47-39500/output/model.tar.gz)\n",
      "x model_algo-1\n",
      "x state_7ce55d39-42e3-4dc5-a503-2dff0a5e28c0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot()\n",
    "colors = ['b', 'g', 'r']\n",
    "markers = ['o', 'v', 's']\n",
    "models = {}\n",
    "distortions = []\n",
    "\n",
    "for k in K:\n",
    "    s3_client = boto3.client('s3')\n",
    "    key = 'kmeans_example/output/' + output_folder +'/' + output_folder + str(k) + '/output/model.tar.gz'\n",
    "    s3_client.download_file(bucket, key, 'model.tar.gz')\n",
    "    print(\"Model for k={} ({})\".format(k, key))\n",
    "    !tar -xvf model.tar.gz \n",
    "    kmeans_model = mx.ndarray.load('model_algo-1')\n",
    "    kmeans_numpy = kmeans_model[0].asnumpy()\n",
    "    #print(kmeans_numpy.shape)\n",
    "    #break\n",
    "    distortions.append(sum(np.min(cdist(descriptors, kmeans_numpy, 'euclidean'), axis=1)) / descriptors.shape[0])\n",
    "    models[k] = kmeans_numpy\n",
    "    \n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('distortion')\n",
    "plt.title('Elbow graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading up on the elbow method, anywhere between 200-300 might be a good start for choosing K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model with K  = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_300_path = 'kmeans_example/output/kmeans-lowlevel-2019-03-18-07-47-39/' + \\\n",
    "    'kmeans-lowlevel-2019-03-18-07-47-39300/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x state_c5726545-cf1b-4569-92be-c381c0b13986\r\n",
      "x model_algo-1\r\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(bucket, model_300_path, 'model.tar.gz')\n",
    "!tar -xvf model.tar.gz\n",
    "model_300 = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 128)\n"
     ]
    }
   ],
   "source": [
    "model_300 = model_300[0].asnumpy()\n",
    "print(model_300.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_to_visual_words(labels, K=1000):\n",
    "    label_counts = np.zeros(1000)\n",
    "    for k in range(1,K-1):\n",
    "        count = np.where(labels == k)[0].shape[0]\n",
    "        label_counts[k-1] = count\n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dog image descriptors to visual dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2492\n"
     ]
    }
   ],
   "source": [
    "# Load pre-computed descriptors and translate to dictionary\n",
    "prefix = 'train-descriptors/'\n",
    "i = 0\n",
    "x_trans = None\n",
    "for file in dogs:\n",
    "    i += 1\n",
    "    with open(prefix+file, 'rb') as pf:\n",
    "        dog = pickle.load(pf)\n",
    "        \n",
    "    desc = np.array([desc[8] for desc in dog['kpd']])\n",
    "    \n",
    "    y = np.argmin(cdist(desc, model_300, 'euclidean'), axis=1)\n",
    "    \n",
    "    x = np.bincount(y, minlength=300)\n",
    "    \n",
    "    if x_trans is None:\n",
    "        x_trans = x\n",
    "    else:\n",
    "        x_trans = np.vstack((x_trans, x))\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert cat image descriptors to visual dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507\n"
     ]
    }
   ],
   "source": [
    "# Load pre-computed descriptors and translate to dictionary\n",
    "prefix = 'train-descriptors/'\n",
    "i = 0\n",
    "x_trans_c = None\n",
    "for file in cats:\n",
    "    i += 1\n",
    "    with open(prefix+file, 'rb') as pf:\n",
    "        cat = pickle.load(pf)\n",
    "        \n",
    "    desc = np.array([desc[8] for desc in cat['kpd']])\n",
    "    \n",
    "    y = np.argmin(cdist(desc, model_300, 'euclidean'), axis=1)\n",
    "    \n",
    "    x = np.bincount(y, minlength=300)\n",
    "    \n",
    "    if x_trans_c is None:\n",
    "        x_trans_c = x\n",
    "    else:\n",
    "        x_trans_c = np.vstack((x_trans_c, x))\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2507, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trans_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((x_trans, x_trans_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((np.ones(2492), np.zeros(2507)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dense = tfidf.transform(X_train).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 300)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dense.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fte = os.listdir('train-descriptors/')[7000:8000]\n",
    "dogs_te = [f for f in fte if f.find('dog') != -1]\n",
    "cats_te = [f for f in fte if f.find('cat') != -1]\n",
    "\n",
    "prefix = 'train-descriptors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n"
     ]
    }
   ],
   "source": [
    "# Load pre-computed descriptors and translate to dictionary\n",
    "prefix = 'train-descriptors/'\n",
    "i = 0\n",
    "xte_trans = None\n",
    "for file in dogs_te:\n",
    "    i += 1\n",
    "    with open(prefix+file, 'rb') as pf:\n",
    "        dog = pickle.load(pf)\n",
    "        \n",
    "    desc = np.array([desc[8] for desc in dog['kpd']])\n",
    "    \n",
    "    y = np.argmin(cdist(desc, model_300, 'euclidean'), axis=1)\n",
    "    \n",
    "    x = np.bincount(y, minlength=300)\n",
    "    \n",
    "    if xte_trans is None:\n",
    "        xte_trans = x\n",
    "    else:\n",
    "        xte_trans = np.vstack((xte_trans, x))\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n"
     ]
    }
   ],
   "source": [
    "# Load pre-computed descriptors and translate to dictionary\n",
    "prefix = 'train-descriptors/'\n",
    "i = 0\n",
    "xte_trans_c = None\n",
    "for file in cats_te:\n",
    "    i += 1\n",
    "    with open(prefix+file, 'rb') as pf:\n",
    "        dog = pickle.load(pf)\n",
    "        \n",
    "    desc = np.array([desc[8] for desc in dog['kpd']])\n",
    "    \n",
    "    y = np.argmin(cdist(desc, model_300, 'euclidean'), axis=1)\n",
    "    \n",
    "    x = np.bincount(y, minlength=300)\n",
    "    \n",
    "    if xte_trans_c is None:\n",
    "        xte_trans_c = x\n",
    "    else:\n",
    "        xte_trans_c = np.vstack((xte_trans_c, x))\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack((xte_trans, xte_trans_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dense = tfidf.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.09514909, 0.        , 0.03915284, ..., 0.0291558 , 0.09425389,\n",
       "         0.12373131],\n",
       "        [0.01390993, 0.02086919, 0.06009977, ..., 0.02557388, 0.02755812,\n",
       "         0.01808839],\n",
       "        [0.03530266, 0.08827481, 0.        , ..., 0.04867885, 0.01748526,\n",
       "         0.02295369],\n",
       "        ...,\n",
       "        [0.06197601, 0.06198877, 0.        , ..., 0.11394501, 0.03069646,\n",
       "         0.08059324],\n",
       "        [0.0274084 , 0.        , 0.03383479, ..., 0.05039127, 0.08145158,\n",
       "         0.03564172],\n",
       "        [0.        , 0.02329417, 0.05749998, ..., 0.06422746, 0.02307026,\n",
       "         0.03028537]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.concatenate((np.ones(502), np.zeros(498)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 300)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(range(0,5000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "ix = shuffle(list(range(0,4999)), random_state=3)\n",
    "X_train_sh = X_train_dense[ix]\n",
    "y_train_sh = y_train[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trekendrick/.virtualenvs/py3cv4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_sh, y_train_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = lr.predict(X_train_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752750550110022"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train_sh, pred_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_te = lr.predict(X_test_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.739"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 300)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.vstack((X_train_sh, X_test_dense))\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_all = np.concatenate((y_train_sh, y_test))\n",
    "y_all = y_all.reshape((len(y_all),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X_all).to_csv('x-all.csv')\n",
    "pd.DataFrame(y_all).to_csv('y-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0_all = np.concatenate((pred_tr, pred_te))\n",
    "f0_all = f0_all.reshape((len(f0_all), 1))\n",
    "f0_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(f0_all).to_csv('f0-all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trekendrick/.virtualenvs/py3cv4/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_sh, y_train_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6122"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tr = svm.predict(X_train_sh)\n",
    "accuracy_score(y_train_sh, pred_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open('datasets/x-train.P', 'wb')\n",
    "#pickle.dump(X_train_sh, file)\n",
    "\n",
    "#file = open('datasets/x-test.P', 'wb')\n",
    "#pickle.dump(X_test_dense, file)\n",
    "\n",
    "#file = open('datasets/y-train.P', 'wb')\n",
    "#pickle.dump(y_train_sh, file)\n",
    "\n",
    "file = open('datasets/y-test.P', 'wb')\n",
    "pickle.dump(y_test, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
